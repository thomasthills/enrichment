---
title             : "Learning, clutter, and age-related cognitive decline: An enrichment-based account of the interdependence between fluid and crystallized intelligence"
shorttitle        : "Enrichment and cognitive aging"

author: 
  - name          : "Thomas T. Hills"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Gibbet Hill Road, Coventry, CV4 7AL, UK"
    email         : "t.t.hills@warwick.ac.uk"

affiliation:
  - id            : "1"
    institution   : "University of Warwick"

authornote: |
  This work was supported by the Alan Turing Institute and Royal Society Wolfson Research Merit Award WM160074.

abstract: |
  Late-life cognitive development is associated with a decline in fluid intelligence which occurs alongside a corresponding increase in crystallized intelligence. Theory often treats these accounts independently, seeing the former as a consequence of biological aging and the latter as a consequence of learning. What has not been fully explored is that lifelong learning may explain both accounts. This article describes a formal enrichment account that shows how a lifetime of experience encodes a cognitive representation that, when used to guide behavior, produces numerous quantitative effects commonly described for cognitive aging: with age,  similarity judgments between concepts fall, free associations become less predictable (higher entropy), and free association networks produced by aggregating output across associates show patterns of declining connectivity. The enrichment account demonstrates how these behavioral outcomes arise when a general prediction error model (Rescorla-Wagner) is used to train a cognitive representation through repeated experience with a structured environment and the cognitive representation is then sampled from to produce behavior. The resulting diffusion of activity and its associated consequences reveal a general property of processes operating over an enriched network and one which speaks directly to cognitive aging. Moreover, as measures of co-activation, rising entropy, falling similarity judgments, and increasing lexical sparseness provide mechanisms for cognitive slowing, over-attention to irrelevant stimuli, and other forms of cognitive clutter, offering an enrichment-based explanation of declining fluid intelligence.  
  
keywords          : "cognitive aging, Rescorla Wagner, spreading activation, network science, free associations, fluid intelligence, crystallized intelligence, cognitive slowing"

bibliography      : /Users/thomashills/Dropbox/Life_3.0_db/Books/BNS_Hills/BNS_Github/enrichment/enrichment.bib 

floatsintext      : yes 
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no
figsintext        : yes

classoption       : "man"
output            : papaja::apa6_pdf
always_allow_html: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library("papaja")
#r_refs("enrichment.bib")
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
# library(DiagrammeR)
# library(tinytex)
 library(igraph)
# library(gridExtra)
# library(grid)
 library(tidyverse)
 library(kableExtra)
# library(igraphdata)
# library(kableExtra)
 library(latex2exp)
library(moments)
# library(scales)
# library(cowplot)
# library(nlme)
# library(gridGraphics)
# library(fitdistrplus)
# library(RColorBrewer)
# library(BayesFactor)
# library(ggpubr)
# library(stargazer)
 library(Rmisc)
 library(lsa)
# library(corrplot)
# library(ggraph)
# library(network)
# library(sna)
```

Cognitive aging across the adult lifespan is characterized by two distinct and well-documented patterns. As individuals age, measures of working memory, processing speed, and long-term memory show performance decrements from approximately age 20, while at the same time, measures of vocabulary and other kinds of general knowledge increase [@Salthouse:2004is;@salthouse2019trajectories; @park2009adaptive;@brysbaert2016many]. This distinction between the ability to solve novel problems in a fast and accurate way, called *fluid intelligence*, and the quantity of one's prior knowledge, called *crystallized intelligence*, is a classic division of intelligence [@cattell1987intelligence]. This division also characteristically distinguishes the old from the young.  Might this division share a common cause? The evidence I provide below suggests that the answer is yes: the outcome of enriching one's cognitive representation through a lifetime of experiencing associations in the world increases competition between associates and produces a relative decline in activation between any two concepts chosen at random. Before demonstrating how this effect arises, I first highlight the primary alternative accounts of aging this work addresses and then  describe the behavioral effects we hope to explain. 

# Degradation or enrichment

Cognitive aging is a rich process with evidence supporting a wide range of phenomenology and theoretical explanations [@reuter2008neurocognitive;@koen2019neural;@spreng2021exploration;@cao2014topological;@grady2006age;@Troyer:1997tt;@mata2007aging]. Much of this work is interpreted as supporting either degradation-based accounts (e.g., involving declining executive function associated with biological aging) or enrichment-based accounts (e.g., involving consequences of lifelong learning), and sometimes both. This dichotomy between degradation and enrichment is well characterized by the distinction between fluid and crystallized intelligence.

Declines in fluid intelligence are often seen as independent of rising crystallized intelligence. One prominent explanation for declines in fluid intelligence is the common cause theory of age-related cognitive decline, which argues that biological aging in the brain is the source of processing speed deficits [@deary2009age]. The supposition is that aging is a general process of degradation, in which factors like oxidative stress and telomere shortening damage the physiological architecture underpinning cognitive performance. @salthouse2013mechanisms describes some potential mechanisms as follows: "a slower speed of transmission along single (e.g., loss of myelination) or multiple (e.g., loss of functional cells dictating circuitous linkages) pathways, or. . . delayed propagation at the connections between neural units (e.g., impairment in functioning of neurotransmitters, reduced synchronization of activation patterns)" (p. 116). Consistent with this, percent volume of grey and white-matter declines in late life [@giorgio2010age; @ge2002age]. Cortical thickness also declines in combination with increases in cerebrospinal fluid space [@lemaitre2012normal].  

Evidence of apparent degradation extends to studies of brain-wide integration. For example, measures of the neural connectome--—the wiring diagram of the brain--—indicate declining local community structure and a reduction in functional segregation [@damoiseaux2017effects; @cao2014topological; @riedel2022trajectory;@ferreira2016aging].  This dedifferentiation is marked by "reduced within-network and increased between-network functional connectivity" [@deery2023older], a result we will see mirrored in the free association data described below. Evidence that this dedifferentiation is caused by degradation is however mixed.  Across studies, brain atrophy frequently explains limited variance in functional desegregation and the two are often statistically uncorrelated [@ferreira2016aging; @geerligs2015brain]. The limited nature of this relationship between degradation and decline is found elsewhere as well, even in more direct studies.  Posthumous evidence of Alzheimer’s and other neurodegenerative and cerebrovascular disease account for around 40% of declines in fluid intelligence (e.g., the Mini-Mental State Examination), leaving substantial variance unexplained [@boyle2021degree]. 

<!--   By these accounts, declines in fluid intelligence are a natural consequence of an enrichment of prior knowledge. This is proposed to arise either because learning strengthens prior associations which, when violated by new experiences, become harder to overcome [e.g., @ramscar2014myth] or because prior experiences 'clutter' knowledge in a way that limits the speed with which old knowledge can be accessed [@buchler2007modeling;@amer2022cluttered]. -->

<!-- There are many cognitive and brain related changes that are consistent with both degradation and enrichment accounts. For example, brain activity changes across the lifespan in relation to encoding and task processing, showing increased contributions from the default-mode network [@grady2006age]. This phenomenology is also associated with decreased modularity within brain regions combined with larger interconnectivity between regions in later life [@geerligs2015brain; @spreng2019shifting]. Spreng and Turner (2019) argue that these changes underpin a lifelong transition from exploration via fluid intelligence to exploitation focused on past knowledge [see also @spreng2021exploration]. -->

A different approach to explaining age-related cognitive decline has involved proposing a causal interdependence between the positive consequences of learning associated with crystallized intelligence and the resulting negative consequences for fluid intelligence. For example, @buchler2007modeling showed using simulations that if they assumed that the number of relations between concepts increased over the lifespan this would lead to more diffuse activation between concepts. Similarly, @ramscar2014myth demonstrated how associations would change through repeated learning, explaining age-related declines in paired-associate learning. Basing their work on @desrosiers1986paired study of paired-associate learning in older adults, which found that older adults perform most poorly on pairs that are least consistent with their prior experience, Ramscar et al. (2014) demonstrated that the difficulty of learning unrelated word pairs is entirely predictable from the co-occurrence frequency of those pairs in past experience. Training a Rescorla-Wagner model on typical patterns of word co-occurrences, unrelated word pairs become negatively associated over time, impairing their future learning.

Still more recent work has argued for a much broader influence of age-related mental "clutter," which may arise from representational changes across the lifespan as well as changes in cognitive control at the time of encoding or retrieval [@amer2022cluttered;@weeks2020holding]. According to this account, over-attending to a diversity of stimuli alongside an inability to filter out past experience can lead older adults to attend to too much information. This in turn creates processing difficulties, especially when that information turns out to be irrelevant. This may extend to the development of the cognitive representation across the lifespan. @li2022diachronic found that older individuals were more likely to show processing difficulties for words that changed their meaning during their lifetime, a property not found in younger individuals who were too young to experience the change. 

The different accounts describe above can be broadly categorized as degradation and nrichment accounts, and the evidence for both is compelling.  However, to what extent we subscribe to one explanation over another should largely depend on the plausibility of their mechanisms and the sufficiency of what they explain. To my knowledge, degradation accounts have not provided formal computational mechanisms for how degradation might lead to the observed age-related changes in healthy individuals. Presumably such mechanisms could be developed and would offer useful predictions. For example, @BorgeHolthoefer:2011bg have developed a compelling model of degradation for hyper-priming in Alzheimer's patients, but similar models for healthy aging are still needed [see also @stella2020multiplex]. A key challenge for formal degradation models is that they would need to explain how degradation alters fluid intelligence but not crystallized intelligence. 

On the other hand, enrichment explanations have either assumed more connectivity [e.g., @buchler2007modeling] or evaluated how differential experience impairs future learning [e.g., @ramscar2014myth]. As called for by @wulff2019new, what is lacking is a full model of representational development and behavior across the adult lifespan. This would represent a computational prediction for what we should expect from lifelong enrichment and what remains to be explained by degradation. This is what I hope to achieve here.  To benchmark such a model, we can use a number of empirical observations made over the last decade.

# The aging lexicon, entropy, and similarity

Several efforts to chart the mental lexicon across the lifespan have identified reproducible trends. @dubossarsky2017quantifying asked over 8000 people, ranging in age from roughly 10 to 70, to provide three free associates to each of 420 cue words. With approximately 1000 people in each decadal age group, data was aggregated within age-groups to produce networks among the 420 cue words with edges representing a weighted function of common associates. After removing edges below a threshold, older networks were found to be more sparsely connected. They had a lower average degree (number of associations per word) higher average shortest path length (greater distance between associates), and lower average clustering coefficient (the proportion of a concept's neighbors that are themselves connected). Evidence also identified a rising entropy for associations, with associates becoming less predictable across the lifespan. Both @zortea2014graph and @wulff2022using found similar patterns of declining connectivity with varying numbers of participants and cues.

Analyses of memory search in older and younger adults also finds consistent patterns of change in the aging mental lexicon. Using a semantic fluency task (e.g., "name all the animals you can think of"), @wulff2022structural constructed lexical networks by connecting words that appeared nearby in the lists that older and younger adults produced. Older adults' produced less well-connected networks, similar to the patterns for free associations described above. @hills2013mechanisms modeled semantic fluency data from adults across the lifespan and found that, compared with younger adults, older adults produced strings of animal names that were less predictable, one from the next. Finally, @cosgrove2021quantifying used percolation analysis to investigate the resilience of older adults' mental lexicons by artificially removing connections between words and found that older adults' lexicons were less resilient to decay. These findings are all suggestive of more sparse and unpredictable connectivity in the outputs retrieved from the mental lexicon.

While free associations may be seen to tap into more fast and automatic processing, slower judgments of similarity between words are also consistent with the above patterns.  @wulff2022structural asked younger and older adults to judge the similarity of 77 different animals over a period of several weeks using a tablet participants took to their homes. Rating the similarity of pairs of animals on a scale from 1 to 20, they found that older adults rated animals as less similar to one another than did young adults. Again, this indicates a sparsening of the connectivity between concepts in the mental lexicon.

The above results indicate that older adults produce less predictable associations (higher entropy), lower similarity judgments, and show evidence of sparsening free association networks. These results are intuitively consistent with representational degradation: one may imagine that a sparseness in output reflects a sparseness in the underlying representation, which is in turn caused by degradation in the neural architecture that underpins it. However, without understanding what we might expect from lifelong learning, efforts to explain cognitive aging as the result of degradation may attempt to bridge an explanatory gap that does not exist. 
Moreover, degradation accounts may even get the causation backwards. Which is to say, if life experience gives rise to some of the primary markers of age-related cognitive decline, they may also contribute to changes in the brain we associate with age-related cognitive decline. 
As demonstrated below, by extending standard learning and retrieval models across the lifespan,  we can predict all of the above effects---rising entropy, falling similarity, and sparsening free association networks---as a consequence of enrichment, without the need for assuming any additional processes associated with biological aging or degradation.
 
# The enrichment account 

The enrichment account envisions behavior as the outcome of learning relationships from the environment to develop a cognitive representation, and then using this representation to generate behavior. This follows calls from previous researchers to model not only the representation but the processes that access that representation to generate behavior [@estes1975some;@johns2023scalable;@jones2015hidden;@castro2020contributions;@hills2022mind]. Formally, the enrichment account involves modeling three separate components:

1.  *Environment*: The environment presents the set of all possible associations that could be learned.
2.  *Representation*: Learning associations from the environment generates a cognitive representation, which continues to develop across the lifespan.
3.  *Behavior*: Behavior involves the recovery of information from the cognitive representation appropriate to the environmental context. This generates free-associations, memory search, similarity judgments, and so on.

To make this relationship clear, these stages are presented in Figure \@ref(fig:Figure1) and each are explained in detail below. The R code to reproduce the environments, the learning of cognitive representations, the behavior, and all analyses and figures in this manuscript are available at https://github.com/thomasthills/enrichment.

```{r Figure1, fig.cap="The process of translating experience with the environment into behavior. Arrows represent processes that translate one domain into another.  Learning translates experience with the environment into a cognitive representation. Additional cognitive processes then act on the representation to generate behavior."}
library(DiagrammeR)

grViz(diagram = "digraph flowchart {
  graph[rankdir=LR]
  node [fontname = arial, shape = square, cex = 1, fixedsize=TRUE, width=2.3]
  tab1 [label = '@@1']
  tab2 [label = '@@2']
  tab3 [label = '@@3']
  
  tab1 -> tab2 -> tab3;
}
  
  [1]: 'Environment'
  [2]: 'Representation'    
  [3]: 'Behavior'    
  ")
```

## Environment

The environment is represented here as network of concepts (e.g., nodes), with the edges (links) between concepts indicating associations that can be learned. This follows the basic idea that things in the world predict one another and in experiencing the world we learn those relationships. The qualitative pattern of behavioral results described below are not dependent on the specific structure of the environment. To demonstrate this, I use a general framework for network construction. This is a variation of a fitness-based network model [@menczer2020first], except that  all concepts are present at the start and edges are formed using rank-based sampling.  Each concept is assigned a rank, $r$, from 1 to the number of concepts, $n$. Then pairs of concepts are chosen, each with probability $P \propto r^{-a}$, and one is added to the edge weight between them. When $a=1$, this process produces a weighted scale-free network, which is characterized by a long-tail in which most concepts have very few associations and a few have very many.  This structure is consistent with the ubiquity of scaling laws in the cognitive sciences and the natural world [@kello2010ga;@johns2010evaluating]. To provide a useful point of comparison, when $a=0$ the resulting network approximates a weighted Erdös-Renyi random graph, in which all nodes are connected with equal probability. 

The estimate of the number of concepts people know in late life varies widely. A factor of 10 estimate is generally around 100,000, though this increases across the lifespan [@brysbaert2016many]. The number of relationships that people experience is harder to estimate, as it depends both on the environment and people's ability to recognize them. In practice, humans report only a subset of all potential associations [@nelson2004university;@de2019small]. For example, the number of associations people reported between the approximately 12,000 cues provided in @de2019small is $~0.15 \%$ of the approximately 72 million possible associations. These are unlikely to represent all possible learnable relationships in the environment or even in their cognitive representation. For example, people do not provide "eyes" as an associate of "koala", though most people probably see koalas with eyes about as often as they see koalas. This makes predicting the number of relationships in the environment based on empirical data problematic. However, to address this, the Supplementary Material demonstrates that the qualitative pattern of results presented here is not altered by substantially increasing or decreasing the number of associations sampled to construct the environment.

For the purposes of demonstration, $n=500$ concepts are used. From these concepts, $2000$ pairs of concepts are sampled with replacement to form the environment and weighted relationships are formed between them, with the weight corresponding to the number of times the pair is chosen across the $2000$ samples. The relationships in the environmental network are therefore represented by weighted and undirected edges. Figure \@ref(fig:Figure2) presents two example environmental networks and their weighted degree (strength) distributions for the different values of $a$. 


```{r Figure2,fig.cap="The structure of the environment from which learning takes place. Two network types are shown: A weighted scale-free network ($a=1$) and a weighted Erdös-Renyi random graph ($a=0$). Each network has 500 concepts (or nodes) and the weighted edges between them are the result of repeatedly sampling 2000 pairs of nodes and adding 1 to the edge weight between the pairs. The strength distributions (sum of the edge weights) are shown to help communicate the difference in the underlying structure.", eval = TRUE, fig.height=5.5, fig.width=5}

#### Figure 2: Environment Structure ####

# Clean and Prepare Workspace 

rm(list=ls())
set.seed(1)

# Rescorla Wagner function 

rescorlaWagner <- function(vmat = vmat, cue, outcome, alpha=1, beta=.2) {
  # cue can be compound: e.g., cue = c("A", "B")
  # outcome can be compound: e.g., outcome = c("A", "B")
  cuevalues <- matrix(vmat[cue, ], nrow = length(cue))
  valueSums <- apply(cuevalues,2,sum )     # cumulative cue value
  # lambda = 1 when present 0 when absent
  lambda = as.numeric(rownames(vmat) %in% outcome)
  pError <- lambda - valueSums     # prediction error = observed - expected
  valueChange <- alpha * beta * pError # value change 
  vmat[cue, ] <- t(t(vmat[cue, ]) + valueChange)                   # update value
  return(vmat)
}

# Environment Parameters #

# World parameters (500/2000/200 for)
wordsInWorld=500
# proportion
# 2000/(600*599/2) # ~1% of all edges
Associates = 2000 # Edges in environment
# Set learning events and age classes
learningEvents <- 200 
ageEpochs = 4

# Build Rank-Based Network Environment 

x <- 1:wordsInWorld
a = 1 # set to .1 for ranking and 0 for ER with fixed number
pairs <- c()
for(i in 1:Associates){
  pairs <- rbind(pairs, sample(x, size = 2, prob=x^(-a), replace = FALSE))
}

# Build ER Network Environment

x <- 1:wordsInWorld
a = 0 # set to 1 for ranking and 0 for ER with fixed number
pairser <- c()
for(i in 1:Associates){
  pairser <- rbind(pairser, sample(x, size = 2, prob=x^(-a), replace = FALSE))
}

set.seed(1)
par(mfrow=c(2,2))
par(mar=c(1,1,1,1))

# Plot Rank environment 

ii <- graph_from_edgelist(pairs,directed=FALSE) 
E(ii)$weight <- 1
ii <- graph_from_adjacency_matrix(get.adjacency(ii), weighted=TRUE, mode = "undirected")
plot(ii, vertex.size = 1, edge.arrow.size = 0, vertex.label = NA, layout = layout_with_fr(ii), main = TeX("$a = 1$"), edge.color=alpha("black", .1) )
# text(-.9,.9, TeX("$\\alpha= 1.0$"))
par(mar=c(5,5,2,2))
#plot(x=1:length(V(ii)), y=degree(ii)[order(degree(ii), decreasing = TRUE)], log="xy", ylab="Degree", xlab="Rank", pch = 16, cex = .5, ylim=c(1,1000))
# strength
plot(x=1:length(V(ii)), y=strength(ii)[order(strength(ii), decreasing = TRUE)], log="xy", ylab="Strength", xlab="Rank", pch = 16, cex = .5, col = alpha("black", .5), ylim=c(1, 1000) )

# Plot ER environment 

set.seed(1)
par(mar=c(3,3,3,3))
iier <- graph_from_edgelist(pairser,directed=FALSE)
E(iier)$weight <- 1
iier <- graph_from_adjacency_matrix(get.adjacency(iier), weighted=TRUE, mode = "undirected")
plot(iier, vertex.size = 1, edge.arrow.size = 0, vertex.label = NA, layout = layout_with_fr(iier),edge.width=E(iier)$weight, edge.color=alpha("black", .1) , main = TeX("$a = 0$"))
#text(0,-1.5, "Training network")
par(mar=c(5,5,2,2))
#plot(x=1:length(V(iier)), y=degree(iier)[order(degree(iier), decreasing = TRUE)], log="xy", ylab="Degree", xlab="Rank", pch = 16, cex = .5, col = alpha("black", .5), ylim=c(1, 20) )
# strength
plot(x=1:length(V(iier)), y=strength(iier)[order(strength(iier), decreasing = TRUE)], log="xy", ylab="Strength", xlab="Rank", pch = 16, cex = .5, col = alpha("black", .5), ylim=c(1, 20) )
```


## Representation

Cognitive representations are built from experience with the environment. This is modeled here as sampling and then learning about relationships in the environment. I use the prediction error framework set out in the Rescorla-Wagner model [@rescorla1972theory] to encode properties of the environment into a cognitive representation. The choice of the Rescorla-Wagner model follows the substantial evidence for learning as a process of minimizing prediction error, which is a fundamental assumption among models of reinforcement learning [@sutton2018reinforcement; @dayan2005theoretical; @mcclelland1981interactive; @hoppe2022exploration]. The Rescorla-Wagner model captures this phenomenology---including associative learning, blocking, inhibition, and extinction---and it is a model on which many subsequent models have been based [e.g., @sutton1981toward]. Though it is not without limitations [@yau2023rescorla;@miller1995assessment], these limitations are largely irrelevant here and the Supplementary Material shows that removing one point of controversy (the context cue) does not alter the results. I therefore use the model to capture the generic prediction-error process inherent in the Rescorla-Wagner design and in recognition of its extreme predictive utility [@soto2023rescorla; @roesch2012surprise;@miller1995assessment;@trimmer2012does].

Formally, the Rescorla-Wagner model minimizes the prediction error between the values of an observed outcome, $j$, and a cue predictive of that outcome, $i$. The value associated with the outcome is $\lambda_j$ and the value for that outcome as predicted by the cue is $V_{i \rightarrow j}$. The prediction error is the difference between them, $(\lambda_j-V_i)$, and it is minimized following each learning event according to the following rule:

$$
\Delta V_{i \rightarrow j} = \alpha_i \beta_j (\lambda_{j} - V_{i \rightarrow j})
$$

The parameter $\alpha_i$ corresponds to cue salience (some cues are easier to learn about than others) and $\beta_j$ to the learning rate for outcomes (some outcomes are learned about faster than others). Both $\alpha$ and $\beta$ values are confined to values between $0$ and $1$. After learning at time $t$, the updated cue value is

$$
V_{i \rightarrow j, t+1} = V_{i \rightarrow j, t} + \Delta V_{i \rightarrow j, t}
$$

Thus, with repeated experience, $V_{i \rightarrow j}$ will approach the observed value $\lambda_j$. This follows exactly the formalization set out in prior work [@rescorla1972theory; @ramscar2017mismeasurement].  

The cognitive representation is formed by applying the Rescorla-Wagner model to the environment in the following way. Each learning event randomly samples a relationship (i.e., edge) from the environment in proportion to its weight (the number of times it was sampled during the environment's construction). Of the two concepts associated with the relationship, one is randomly assigned as the cue and the other as the outcome. The representation is then updated according to the Rescorla-Wagner model. Here, we let all outcomes be equivalent and associated  with $\alpha=1$ and $\lambda=1$. To demonstrate that the qualitative results are not dependent on the precise learning values, $\beta$ is varied from $.01$ to $.1$ in the manuscript, and over its entire range in the Supplemental material, consistently reproducing the pattern described here.

To simulate development, learning occurs in 4 epochs each with 200 learning trials.  The precise number of learning trials per epoch is unrelated to the qualitative pattern of results. As demonstrated in the Supplemental Material, the gradient of change is always in the direction specified below, though it reduces with increased learning. Figure \@ref(fig:Figure3) provides examples of two learning representations over the four epochs for the different network types ($a=0$ and $a=1$) and $\beta=.01$.  This moves from sparse connectivity on the left, to highly interconnected “hairballs” on the right. 

Table \@ref(tab:statsForReps) quantifies what can be seen in Figure \@ref(fig:Figure3) by showing the mean values for 1000 simulated environments and the resulting learned cognitive representations. Note that more learning leads to increasing interconnectivity in the representation. The total number of nodes with associations increases, indicating a rising conceptual vocabulary. The total number of associations increases, as measured by the total number of edges and mean degree. The strength of associations increases, as measured by the sum of a concepts weighted edges with other concepts.  The average shortest path length falls, meaning that concepts become closer to one another (except in epoch 1 for $a=0$ when there are still many disconnected associative islands, or network components). And the clustering coefficient increases, meaning that the neighbors of concepts tend to be connected among themselves. Overall, this is the opposite pattern to that described for the free association networks in the introduction, which become more sparsely connected with age. Critically, however, we must sample from these representations to produce behavior.


```{r Figure3, eval = TRUE, fig.cap="Examples of the growing mental lexicon resulting from training a Rescorla-Wagner model on the network types shown in Figure 2. Training occurs in 200 event epochs, with edges from the environment sampled in proportion to their weight. Nodes represent individual concepts and edges represent learned associations. Unlearned 'isolates' are not shown in the visualization but decline with age: Across the four epochs, the number of isolates is $333$, $262$, $222$, and $191$ for $a=1$ and $239$, $123$, $63$, and $41$ for $a=0$, consistent with a rising vocabulary.", cache=TRUE}
set.seed(1)
#### Figure 3: Cognitive Representation ####

# Build Representation: Learn from Environment

# Size of Network and Learning Trials 

# a = 1

betav = .01

# Remove isolates? (set to 1 for removal or 0 for inclusion)

remiso = 1

#x <- seq(1000, 10000, 1000)
y <- rep(1000, length(x))

# Plot pars
par(mfrow=c(2,ageEpochs))
par(mar=c(2,2,2,2))


iis <- ii

# Prepare Representation Matrix 

n = length(V(iis))+1 # number of cues (words) + context cue

# initialize zero value matrix for learning
vmat <- matrix(0, nrow = n, ncol = n)
rownames(vmat) <- 1:n
colnames(vmat) <- 1:n

# initialize metrics
edgeE <- rep(NA, ageEpochs)
nodeCount <- rep(NA, ageEpochs)
ageNetworkList <- list(NULL)

# Learn Representation 

for(lage in 1:ageEpochs){
  # take fraction of environment that is learnable 
  #ageWords <- round(wordsInWorld*y[lage]/y[length(y)])
  ageWords <- wordsInWorld
  # make training data set
  traindata <- c()
  # sample edges from environment
  for(i in 1:learningEvents){
   traindata <- rbind(traindata, cue_outcome <- ends(iis, sample(E(iis), 1, prob=E(iis)$weight))) 
  }
  # keep list of first words learned in year 1
  if(lage == 1){
    firsttraindata <- traindata
  }
  # train on cue-outcome pairs
  for(i in 1:learningEvents){
    cue_outcome <- traindata[i,]
    cue_outcome<- sample(as.vector(cue_outcome))
    vmat <- rescorlaWagner(vmat, cue=c(n, cue_outcome[1]), outcome=cue_outcome[2], beta = betav) 
  }
 # make undirected graph from representation 
  gle <- graph_from_adjacency_matrix(vmat, weighted=TRUE, diag=FALSE, mode = "undirected")
  # remove context cue
  gle <- igraph::delete_vertices(gle, n)
  nodeCount[lage] <- length(V(gle))
  # save learned representation
  ageNetworkList[[lage]] <- gle
  # copy network
  g2 <- gle
  # get symmetric weighted network 
  weightMatrix <- as_adjacency_matrix(g2, attr="weight", sparse=FALSE)
  # set negative values to zero
  weightMatrix[weightMatrix < 0] <- 0
  # normalize rows for entropy
  ww<-weightMatrix/rowSums(weightMatrix, na.rm=TRUE)
  # entropy function
  entropy <- function(p) rowSums(-(p * log(p)), na.rm = TRUE)
  # compute entropy for each node
  node_entropy <- entropy(ww) 
  
  # only compute entropy for words learned about at time 1 (removes isolates with 0 entropy)
  ftlist <- unique(c(firsttraindata[,1], firsttraindata[,2]))
  # take median entropy of list
  edgeE[lage] <- mean(node_entropy[ftlist])
  # remove edges with 0 or less weight
  g2 <- igraph::delete.edges(gle, which(E(gle)$weight <=0.0))
  # set remaining weights to 1
  E(g2)$weight <- 1
  
  # if remove isolates
  if(remiso==1){
    isolated = which(igraph::degree(g2)==0)
    #print(paste("isolates for age ", lage, " are ", length(isolated), sep = " "))
    g2 = igraph::delete.vertices(g2, isolated)  
  }
  # plot learned representation
  plot(g2, vertex.size = 1, edge.arrow.size = 0, vertex.label=NA, layout=layout_with_fr(g2, dim=3), edge.color=alpha("black", .1) )
  # label first one in 'learned'
  if(lage == 1){
    text(0, 1.5, TeX("a = 1"))
  }
  # label all with iterations
  its <- lage*learningEvents
  text(0, -1.5, paste("t =",its))
}


# Build Representation: Learn from Environment 

# Size of Network and Learning Trials 

# a = 0

#x <- seq(1000, 10000, 1000)
y <- rep(1000, length(x))

# Plot pars
par(mar=c(2,2,2,2))


iis <- iier

# Prepare Representation Matrix 

n = length(V(iis))+1 # number of cues (words) + context cue

# initialize zero value matrix for learning
vmat <- matrix(0, nrow = n, ncol = n)
rownames(vmat) <- 1:n
colnames(vmat) <- 1:n

# initialize metrics
edgeE <- rep(NA, ageEpochs)
nodeCount <- rep(NA, ageEpochs)
ageNetworkList <- list(NULL)

# Learn Representation 

for(lage in 1:ageEpochs){
  # take fraction of environment that is learnable 
  #ageWords <- round(wordsInWorld*y[lage]/y[length(y)])
  ageWords <- wordsInWorld
  # make training data set
  traindata <- c()
  # sample edges from environment
  for(i in 1:learningEvents){
   traindata <- rbind(traindata, cue_outcome <- ends(iis, sample(E(iis), 1, prob=E(iis)$weight))) 
  }
  # keep list of first words learned in year 1
  if(lage == 1){
    firsttraindata <- traindata
  }
  # train on cue-outcome pairs
  for(i in 1:learningEvents){
    cue_outcome <- traindata[i,]
    cue_outcome<- sample(as.vector(cue_outcome))
    vmat <- rescorlaWagner(vmat, cue=c(n, cue_outcome[1]), outcome=cue_outcome[2], beta = betav) 
  }
 # make undirected graph from representation 
  gle <- graph_from_adjacency_matrix(vmat, weighted=TRUE, diag=FALSE, mode = "undirected")
  # remove context cue
  gle <- igraph::delete_vertices(gle, n)
  nodeCount[lage] <- length(V(gle))
  # Remove negative edges
  negEdges <- which(E(gle)$weight < 0)
  gle <- igraph::delete_edges(gle, negEdges)
  # save learned representation
  ageNetworkList[[lage]] <- gle
  # copy network
  g2 <- gle
  # get symmetric weighted network 
  weightMatrix <- as_adjacency_matrix(g2, attr="weight", sparse=FALSE)
  # set negative values to zero
  weightMatrix[weightMatrix < 0] <- 0
  # normalize rows for entropy
  ww<-weightMatrix/rowSums(weightMatrix, na.rm=TRUE)
  # entropy function
  entropy <- function(p) rowSums(-(p * log(p)), na.rm = TRUE)
  # compute entropy for each node
  node_entropy <- entropy(ww) 
  
  # only compute entropy for words learned about at time 1 (removes isolates with 0 entropy)
  ftlist <- unique(c(firsttraindata[,1], firsttraindata[,2]))
  # take median entropy of list
  edgeE[lage] <- mean(node_entropy[ftlist])
  # remove edges with 0 or less weight
  g2 <- igraph::delete.edges(gle, which(E(gle)$weight <=0.0))
  # set remaining weights to 1
  E(g2)$weight <- 1
  
    # if remove isolates
  if(remiso==1){
    isolated = which(igraph::degree(g2)==0)
    #print(paste("isolates for age ", lage, " are ", length(isolated), sep = " "))
    g2 = igraph::delete.vertices(g2, isolated)  
  }
  
  # plot learned representation
  plot(g2, vertex.size = 1, edge.arrow.size = 0, vertex.label=NA, layout=layout_with_fr(g2, dim=3), edge.color=alpha("black", .1) )
  # label first one in 'learned'
  if(lage == 1){
    text(0, 1.5, TeX("a = 0"))
  }
  # label all with iterations
  its <- lage*learningEvents
  text(0, -1.5, paste("t =",its))
}


```


```{r statsForReps_prep, cache=TRUE}
rm(list=ls())
set.seed(1)

par(mfrow=c(1,2))

# Rescorla Wagner function 

rescorlaWagner <- function(vmat = vmat, cue, outcome, alpha=1, beta=.2) {
  # cue can be compound: e.g., cue = c("A", "B")
  # outcome can be compound: e.g., outcome = c("A", "B")
  cuevalues <- matrix(vmat[cue, ], nrow = length(cue))
  valueSums <- apply(cuevalues,2,sum )     # cumulative cue value
  # lambda = 1 when present 0 when absent
  lambda = as.numeric(rownames(vmat) %in% outcome)
  pError <- lambda - valueSums     # prediction error = observed - expected
  valueChange <- alpha * beta * pError # value change 
  vmat[cue, ] <- t(t(vmat[cue, ]) + valueChange)                   # update value
  return(vmat)
}


# Environment Parameters #

# World parameters (500/2000/200 for)
wordsInWorld=500
# proportion
# 2000/(600*599/2) # ~1% of all edges
Associates = 2000 # Edges in environment
# Set learning events and age classes
learningEvents <- 200
ageEpochs = 4
Simsi =1000 

thingstoTrack <- c("Nodes", "Edges", "Strength", "Degree","ASPL", "C" , "Mean", "Mdn", "Skewness")

# Environment data  
envdata1 <- matrix(NA, nrow = Simsi, ncol = length(thingstoTrack))
envdata0 <- matrix(NA, nrow = Simsi, ncol = length(thingstoTrack))

# Cognivitive representation data
repnodesa1<- matrix(NA, nrow = Simsi, ncol = 4)
repedgesa1<- matrix(NA, nrow = Simsi, ncol = 4)
repstrengtha1<- matrix(NA, nrow = Simsi, ncol = 4)
repdegreea1 <- matrix(NA, nrow = Simsi, ncol = 4)
repaspla1<- matrix(NA, nrow = Simsi, ncol = 4)
repca1<- matrix(NA, nrow = Simsi, ncol = 4)
repmn1<- matrix(NA, nrow = Simsi, ncol = 4)
repmdn1<- matrix(NA, nrow = Simsi, ncol = 4)
repsk1<- matrix(NA, nrow = Simsi, ncol = 4)

repnodesa0<- matrix(NA, nrow = Simsi, ncol = 4)
repedgesa0<- matrix(NA, nrow = Simsi, ncol = 4)
repstrengtha0<- matrix(NA, nrow = Simsi, ncol = 4)
repdegreea0 <- matrix(NA, nrow = Simsi, ncol = 4)
repaspla0<- matrix(NA, nrow = Simsi, ncol = 4)
repca0<- matrix(NA, nrow = Simsi, ncol = 4)
repmn0<- matrix(NA, nrow = Simsi, ncol = 4)
repmdn0<- matrix(NA, nrow = Simsi, ncol = 4)
repsk0<- matrix(NA, nrow = Simsi, ncol = 4)

for(worldsi in 1:Simsi){
  # Build Rank-Based Network Environment 
  
  x <- 1:wordsInWorld
  a = 1 # set to .1 for ranking and 0 for ER with fixed number
  pairs <- c()
  for(i in 1:Associates){
    pairs <- rbind(pairs, sample(x, size = 2, prob=x^(-a), replace = FALSE))
  }
  
  # Build ER Network Environment
  
  x <- 1:wordsInWorld
  a = 0 # set to 1 for ranking and 0 for ER with fixed number
  pairser <- c()
  for(i in 1:Associates){
    pairser <- rbind(pairser, sample(x, size = 2, prob=x^(-a), replace = FALSE))
  }
 
  # Make graph 
  ii <- graph_from_edgelist(pairs,directed=FALSE) 
  E(ii)$weight <- 1
  ii <- graph_from_adjacency_matrix(get.adjacency(ii), weighted=TRUE, mode = "undirected")
  
  iier <- graph_from_edgelist(pairser,directed=FALSE)
  E(iier)$weight <- 1
  iier <- graph_from_adjacency_matrix(get.adjacency(iier), weighted=TRUE, mode = "undirected")
  
  envdata1[worldsi, 1] <- sum(igraph::degree(ii, mode = "total") >= 1)
  envdata1[worldsi, 2] <- length(E(ii))
  envdata1[worldsi, 3] <- mean(igraph::strength(ii, mode = "total"))
  envdata1[worldsi, 4] <- mean(igraph::degree(ii, mode = "total"))
  envdata1[worldsi, 5] <- igraph::mean_distance(ii, unconnected=TRUE)
  envdata1[worldsi, 6] <- mean(igraph::transitivity(ii, type="local"), na.rm=TRUE)
  envdata1[worldsi, 7] <- mean(E(ii)$weight)
  envdata1[worldsi, 8] <- median(E(ii)$weight) 
  envdata1[worldsi, 9] <- skewness(E(ii)$weight)
  
  envdata0[worldsi, 1] <- sum(igraph::degree(iier, mode = "total") >= 1)
  envdata0[worldsi, 2] <- length(E(iier))
  envdata0[worldsi, 3] <- mean(igraph::strength(iier, mode = "total"))
  envdata0[worldsi, 4] <- mean(igraph::degree(iier, mode = "total"))
  envdata0[worldsi, 5] <- igraph::mean_distance(iier, unconnected=TRUE)
  envdata0[worldsi, 6] <- mean(igraph::transitivity(iier, type="local"), na.rm=TRUE)
  envdata0[worldsi, 7] <- mean(E(iier)$weight)
  envdata0[worldsi, 8] <- median(E(iier)$weight) 
  envdata0[worldsi, 9] <- skewness(E(iier)$weight)
  
  #### Figure 3: Cognitive Representation ####
  
  # Build Representation: Learn from Environment
  
  # Size of Network and Learning Trials 
  
  # a = 1
  
  betav = .01
  
  # Remove isolates? (set to 1 for removal or 0 for inclusion)
  
  remiso = 1
  
  y <- rep(1000, length(x))
  
  iis <- ii
  
  # Prepare Representation Matrix 
  
  n = length(V(iis))+1 # number of cues (words) + context cue
  
  # initialize zero value matrix for learning
  vmat <- matrix(0, nrow = n, ncol = n)
  rownames(vmat) <- 1:n
  colnames(vmat) <- 1:n
  
  
  # Learn Representation 
  
  for(lage in 1:ageEpochs){
    # take fraction of environment that is learnable 
    #ageWords <- round(wordsInWorld*y[lage]/y[length(y)])
    ageWords <- wordsInWorld
    # make training data set
    traindata <- c()
    # sample edges from environment
    for(i in 1:learningEvents){
     traindata <- rbind(traindata, cue_outcome <- ends(iis, sample(E(iis), 1, prob=E(iis)$weight))) 
    }
    # keep list of first words learned in year 1
    if(lage == 1){
      firsttraindata <- traindata
    }
    # train on cue-outcome pairs
    for(i in 1:learningEvents){
      cue_outcome <- traindata[i,]
      cue_outcome<- sample(as.vector(cue_outcome))
      vmat <- rescorlaWagner(vmat, cue=c(n, cue_outcome[1]), outcome=cue_outcome[2], beta = betav) 
    }
   # make undirected graph from representation 
    gle <- graph_from_adjacency_matrix(vmat, weighted=TRUE, diag=FALSE, mode = "undirected")
    # remove context cue
    gle <- igraph::delete_vertices(gle, n)
    # Remove negative edges
    negEdges <- which(E(gle)$weight < 0)
    gle <- igraph::delete_edges(gle, negEdges)
    
    repnodesa1[worldsi, lage]<- sum(igraph::degree(gle, mode = "total") >= 1)
    repedgesa1[worldsi, lage] <-  length(E(gle))
    repstrengtha1[worldsi, lage] <- mean(igraph::strength(gle, mode = "total"))
    repdegreea1[worldsi, lage]  <- mean(igraph::degree(gle, mode = "total"))
    repaspla1[worldsi, lage] <-  igraph::mean_distance(gle, unconnected=TRUE)
    repca1[worldsi, lage] <- mean(igraph::transitivity(gle, type="local"), na.rm=TRUE)
    repmn1[worldsi, lage] <- mean(E(gle)$weight) 
    repmdn1[worldsi, lage] <- median(E(gle)$weight)
    repsk1[worldsi, lage] <- moments::skewness(E(gle)$weight) 
    
  }
  
  
  # Build Representation: Learn from Environment 
  
  # Size of Network and Learning Trials 
  
  # a = 0
  
  #x <- seq(1000, 10000, 1000)
  y <- rep(1000, length(x))
  
  # Plot pars
  par(mar=c(2,2,2,2))
  
  
  iis <- iier
  
  # Prepare Representation Matrix 
  
  n = length(V(iis))+1 # number of cues (words) + context cue
  
  # initialize zero value matrix for learning
  vmat <- matrix(0, nrow = n, ncol = n)
  rownames(vmat) <- 1:n
  colnames(vmat) <- 1:n
  
  # initialize metrics
  edgeE <- rep(NA, ageEpochs)
  nodeCount <- rep(NA, ageEpochs)
  ageNetworkList <- list(NULL)
  
  # Learn Representation 
  
  for(lage in 1:ageEpochs){
    # take fraction of environment that is learnable 
    #ageWords <- round(wordsInWorld*y[lage]/y[length(y)])
    ageWords <- wordsInWorld
    # make training data set
    traindata <- c()
    # sample edges from environment
    for(i in 1:learningEvents){
     traindata <- rbind(traindata, cue_outcome <- ends(iis, sample(E(iis), 1, prob=E(iis)$weight))) 
    }
    # keep list of first words learned in year 1
    if(lage == 1){
      firsttraindata <- traindata
    }
    # train on cue-outcome pairs
    for(i in 1:learningEvents){
      cue_outcome <- traindata[i,]
      cue_outcome<- sample(as.vector(cue_outcome))
      vmat <- rescorlaWagner(vmat, cue=c(n, cue_outcome[1]), outcome=cue_outcome[2], beta = betav) 
    }
   # make undirected graph from representation 
    gle <- graph_from_adjacency_matrix(vmat, weighted=TRUE, diag=FALSE, mode = "undirected")
    # remove context cue
    gle <- igraph::delete_vertices(gle, n)
    # Remove negative edges
    negEdges <- which(E(gle)$weight < 0)
    gle <- igraph::delete_edges(gle, negEdges)
    
    # save data
    repnodesa0[worldsi, lage]<- sum(igraph::degree(gle, mode = "total") >= 1)
    repedgesa0[worldsi, lage] <-  length(E(gle))
    repstrengtha0[worldsi, lage] <- mean(igraph::strength(gle, mode = "total"))
    repdegreea0[worldsi, lage]  <- mean(igraph::degree(gle, mode = "total"))
    repaspla0[worldsi, lage] <-  igraph::mean_distance(gle, unconnected=TRUE)
    repca0[worldsi, lage] <- mean(igraph::transitivity(gle, type="local"), na.rm=TRUE)
    repmn0[worldsi, lage] <- mean(E(gle)$weight) 
    repmdn0[worldsi, lage] <- median(E(gle)$weight)
    repsk0[worldsi, lage] <- moments::skewness(E(gle)$weight) 
  }
}

a0dat <- t(matrix(c( formatC(colMeans(repnodesa0), format="f", digits = 2),
formatC(colMeans(repedgesa0), format="f", digits=1),
formatC(colMeans(repstrengtha0),format="f", digits =3),
formatC(colMeans(repdegreea0),format="f", digits = 2),
formatC(colMeans(repaspla0),format="f", digits=3),
formatC(colMeans(repca0), format="f", digits=3),
formatC(colMeans(repmn0), format="f", digits=3),
formatC(colMeans(repmdn0), format="f", digits=3),
formatC(colMeans(repsk0), format="f", digits=3)), nrow=4))

a1dat <- t(matrix(c( formatC(as.numeric(colMeans(repnodesa1), format="f", digits = 2)),
formatC(colMeans(repedgesa1), format="f", digits=1),
formatC(colMeans(repstrengtha1),format="f", digits =3),
formatC(colMeans(repdegreea1),format="f", digits = 2),
formatC(colMeans(repaspla1),format="f", digits=3),
formatC(colMeans(repca1), format="f", digits=3),
formatC(colMeans(repmn1), format="f", digits=3),
formatC(colMeans(repmdn1), format="f", digits=3),
formatC(colMeans(repsk1), format="f", digits=3)), nrow=4))

datout1 <- data.frame(colMeans(envdata0),a0dat)
names(datout1) <- c("Environment", "Epoch 1", "Epoch 2", "Epoch 3", "Epoch 4")
datout2 <- data.frame(colMeans(envdata1), a1dat)
names(datout2) <- c("Environment", "Epoch 1", "Epoch 2", "Epoch 3", "Epoch 4")

datout <- rbind(datout1, datout2)

Measures <- c(thingstoTrack, thingstoTrack )

a <- c(rep("$a=0$", 9), rep("$a=1$", 9))

datout[,1] <- round(datout[,1], 2)
datout <- cbind(a, Measures, datout)
```


```{r statsForReps}

datouts <- datout[-c(7:9,16:18),]
kable(datouts,row.names=FALSE, booktabs = T, escape = FALSE, caption = "Statistics for the environments and growing representations.", col.names = c("$a$", "Measures", "Environment", "1", "2", "3", "4"), font_size = 11) %>% 
  column_spec(4, border_left = TRUE)  %>%
kable_classic(full_width = F, html_font = "Cambria")   %>% 
  add_header_above(c(" " = 3, "Epoch" = 4), bold = TRUE) %>%
  row_spec(6,extra_css = "border-bottom: 1px solid;") %>% 
  collapse_rows(columns = 1) %>% 
  footnote(general = "Measures are averaged over 1000 environments and cognitive representations learned from those environments over four epochs of 200 learning events each. Nodes indicates the total number of non-isolates in the environment or cognitive representation. Strength is the sum of the edge weights. Degree is the number of associations. ASPL is the average shortest path length. C is the mean local clustering coefficient.", threeparttable = TRUE) 

```


# Results: Behavior

The stylized facts associated with cognitive aging we aim to explain are a rising entropy of associations, a reduction in pairwise similarity judgments, and sparsening of the structure of the free association network. Each of these is recovered from the learned cognitive representation as described below. In each case, environments are constructed independently 1000 times and then learning occurs over 4 epochs of 200 trials each.  The Supplementary Material varies all possible parameters and consistently finds the same qualitative patterns as described here.

### Rising entropy

Following past work [@stella2020multiplex;@fradkin2022accumulating;@dubossarsky2017quantifying], we will measure the predictability of associations produced from the cognitive representation using *Shannon's information entropy*. This measures the surprisingness of associative response given the cue. If a cue has only one or a few strongly weighted associations, any given associate will be less surprising than if it has many equally weighted associations. Because each concept is connected to other concepts in the representation by a set of weighted edges, we can compute the entropy for every cue in the network representation as follows:

$$
H = -\sum_{i=1}^{k}  p_i log(p_i)
$$ 

Here, $p_i$ is the proportion of the weight $w_i$ along edge $i$ with respect to all $k$ edges for that cue. That is, $p_i = \frac{w_i}{\sum_k w_k}$. The entropy reported below is the mean entropy across all cues.  This is taken here to represent the entropy that would be recorded if many people produced associations for each cue, which would capture the relative proportions of associations in correspondence with their weights.

The result of this computation is shown in Figure \@ref(fig:Figure4).  For various network constructions and learning rates, the results consistently show that entropy rises with increased learning, following that observed in @dubossarsky2017quantifying. 

### Falling similarity

To simulate similarity judgments, we create a measure of co-activation between pairs of cues using spreading activation, a commonly used approach to measure co-activation in cognitive representations [@vitevitch2021cognitive; @siew2019spreadr;@collins1975spreading]. To do this, we allow spreading activation to leave one node in the pair and measure activation at the other node, $A_{j \rightarrow k}$. This allows us to measure the extent to which one word co-activates the other. Doing this for both cues, we take similarity as the summed co-activation.

$$
S = A_{j \rightarrow k} + A_{j \rightarrow k}
$$

We measure this similarity for a random selection of 20 concept pairs in the representation, for each of 1000 simulations. This only uses concepts learned during the first epoch of learning, ensuring that all concepts are included in the vocabulary for each epoch. Simulations use the `spreadr` function from @siew2019spreadr. This simulates 100 units of activation released from the cue concept, $j$, and divides its activation along each associative edge in proportion to their weights at each time step.  The maximum activation at the target concept over 10 time steps is recorded as $A_{j \rightarrow k}$. Then the cue and target are swapped and the simulation is repeated to capture $A_{j \rightarrow k}$.

The result of this computation is shown in Figure \@ref(fig:Figure4).  For various network constructions and learning rates, the results consistently show that similarity judgments fall with increased learning, following that found in @wulff2019new. 


```{r Fig4ForSaving, fig.cap="The rising entropy and falling similarity of the aging lexicon as a function of learning. ",fig.height=3.4, eval = FALSE, cache = TRUE}

#### Figure 4: Similarity and Entropy ####

# Simulation to recreate environment and cognition and entropy/similarity measures

set.seed(1)

# Rescorla Wagner function 

rescorlaWagner <- function(vmat = vmat, cue, outcome, alpha=1, beta=.2) {
  # cue can be compound: e.g., cue = c("A", "B")
  # outcome can be compound: e.g., outcome = c("A", "B")
  cuevalues <- matrix(vmat[cue, ], nrow = length(cue))
  valueSums <- apply(cuevalues,2,sum )     # cumulative cue value
  # lambda = 1 when present 0 when absent
  lambda = as.numeric(rownames(vmat) %in% outcome)
  pError <- lambda - valueSums     # prediction error = observed - expected
  valueChange <- alpha * beta * pError # value change 
  vmat[cue, ] <- t(t(vmat[cue, ]) + valueChange)                   # update value
  return(vmat)
}


# World parameters (500/2000/200 for)
wordsInWorld=500
Associates = 2000 # Edges in environment
# Set learning events and age classes
learningEvents <- 200 
ageEpochs = 4 
Worlds =10 
Betas = seq(.1,.5, .1)

alphas <- c(0,1)

Elist <- list(NULL)
Slist <- list(NULL)

for(alphai in 1:length(alphas)){
 
  EEB <- matrix(NA, nrow=length(Betas), ncol = ageEpochs)
  SSB <- matrix(NA, nrow=length(Betas), ncol = ageEpochs)
  
  for(bis in 1:length(Betas)){
    # Entropy keeper
    EE <- matrix(NA, nrow=Worlds, ncol = ageEpochs)
    # Similarity keeper
    SS <- matrix(NA, nrow=Worlds, ncol = ageEpochs)
    
    for(woi in 1:Worlds){
        
      # Build the world
      x <- 1:wordsInWorld
      a = alphas[alphai] # set to 1 for ranking and 0 for ER with fixed number
      pairs <- c()
      for(i in 1:Associates){
        pairs <- rbind(pairs, sample(x, size = 2, prob=x^(-a), replace = FALSE))
      }
      # Make graph from pairs
      ii <- graph_from_edgelist(pairs,directed=FALSE) 
      
      # Add isolates if number of vertices is not wordsInWorld 
      difamt = wordsInWorld-length(V(ii))
      if (difamt > 0){
       ii <-  add_vertices(ii,difamt)
      }
      
      # Rename graph for learning representation 
      iis <- ii
      
      # Prepare Representation Matrix 
      
      n = length(V(iis))+1 # number of cues (words) + context cue
      
      # Initialize zero value matrix for learning
      vmat <- matrix(0, nrow = n, ncol = n)
      rownames(vmat) <- 1:n
      colnames(vmat) <- 1:n
      
      # Initialize metrics
      edgeE <- rep(NA, ageEpochs)
      nodeCount <- rep(NA, ageEpochs)
      ageNetworkList <- list(NULL)
      
      # Learn Representation 
      
      for(lage in 1:ageEpochs){
        # take fraction of environment that is learnable 
        #ageWords <- round(wordsInWorld*y[lage]/y[length(y)])
        ageWords <- wordsInWorld
        # make training data set
        traindata <- c()
        # sample edges from environment
        for(i in 1:learningEvents){
          traindata <- rbind(traindata, cue_outcome <- ends(iis, sample(E(iis), 1, prob=E(iis)$weight))) 
        }
        # keep list of first words learned in year 1
        if(lage == 1){
          firsttraindata <- traindata
        }
        # train on cue-outcome pairs
        for(i in 1:learningEvents){
          cue_outcome <- traindata[i,]
          cue_outcome<- sample(as.vector(cue_outcome))
          vmat <- rescorlaWagner(vmat, cue=c(n, cue_outcome[1]), outcome=cue_outcome[2], beta = Betas[bis]) 
        }
        # make undirected graph from representation 
        gle <- graph_from_adjacency_matrix(vmat, weighted=TRUE, diag=FALSE, mode = "undirected")
        # remove context cue
        gle <- igraph::delete_vertices(gle, n)
        nodeCount[lage] <- length(V(gle))
        # save learned representation
        ageNetworkList[[lage]] <- gle
        # copy network
        g2 <- gle
        # get symmetric weighted network 
        weightMatrix <- as_adjacency_matrix(g2, attr="weight", sparse=FALSE)
        # set negative values to zero
        weightMatrix[weightMatrix < 0] <- 0
        # normalize rows for entropy
        ww<-weightMatrix/rowSums(weightMatrix, na.rm=TRUE)
        # entropy function
        entropy <- function(p) rowSums(-(p * log(p)), na.rm = TRUE)
        # compute entropy for each node
        node_entropy <- entropy(ww) 
        
        # only compute entropy for words learned about at time 1 (removes isolates with 0 entropy)
        ftlist <- unique(c(firsttraindata[,1], firsttraindata[,2]))
        # take median entropy of list
        edgeE[lage] <- mean(node_entropy[ftlist])
        # remove edges with 0 or less weight
        g2 <- igraph::delete.edges(gle, which(E(gle)$weight <=0.0))
        # set remaining weights to 1
        E(g2)$weight <- 1
        # plot learned representation
        # plot(g2, vertex.size = 1, edge.arrow.size = 0, vertex.label=NA, layout=layout_with_fr(g2))
        # label first one in 'learned'
        # if(lage == 1){
         #  text(0, 1.5, "Learned lexicon")
        # }
        # label all with iterations
        # its <- lage*learningEvents
        # text(0, -1.5, paste("t =",its))
      }
      # Entropy values to save 
      EE[woi,] <- edgeE
      
      #### Compute and Plot Similarity
      
      # choose target pairs, from first training data (firsttraindata)
      learningPairs = 20 # this 50 random pairs
      simpair <- firsttraindata[sample(seq(1:nrow(firsttraindata)), learningPairs ),]
      # simpair <- firsttraindata # this takes all pairs
      # set initial activation levels
      simpair <- data.frame(simpair, activation = 100)
      
      # time for spreading activation
      tspr <- 10 
      # assign column names
      names(simpair) <- c("node", "node", "activation")
      ## create datastore for similarity judgments
      simJudge <- c()
      ## for each age network
      for(sage in 1:length(ageNetworkList)){
        ## initiate activation at each node and measure activation at the other 
        for(testrow in 1:nrow(simpair)){
          # initiate activation at the cue
          df1 <- spreadr::spreadr(start_run = simpair[testrow,c(1,3)], decay = 0,
                                  retention = 0, suppress = 0,
                                  network = ageNetworkList[[sage]], time = tspr)
          # measure max activation at the target node
          maxActivation12 <- max(subset(df1, node == simpair[testrow,2])$activation)
          # initiate activation at the other cue
          df2 <- spreadr::spreadr(start_run = simpair[testrow,c(2,3)], decay = 0,
                                  retention = 0, suppress = 0,
                                  network = ageNetworkList[[sage]], time = tspr)
          # measure max activation at the target node
          maxActivation21 <- max(subset(df2, node == simpair[testrow,1])$activation)
          # add the max activations
          simval <- maxActivation12 + maxActivation21
          # add results to the data frame
          simJudge <- rbind(simJudge, c(simpair[testrow,1],simpair[testrow,2], simval, sage))
        }
      }
      # ready data frame with results
      simJudge <- data.frame(simJudge)
      # label columns
      names(simJudge) <- c("node1", "node2", "similarity", "age")
      # get stats by age
      sed <- summarySE(simJudge, measurevar="similarity", groupvars="age")
      SS[woi,] <- sed$similarity
    }
    
    msee <- apply(EE, 2, mean)
    sdee <- apply(EE, 2, sd)
    sdee <- sdee/sqrt(nrow(EE))
    mses <- apply(SS, 2, mean)
    sdes <- apply(SS, 2, sd)
    sdes <- sdes/sqrt(nrow(SS))
   
    EEB[bis,] <- msee 
    SSB[bis,] <- mses 
  }
  
Elist[[alphai]] <- EEB
Slist[[alphai]] <- SSB
}

#pdf(file="EntropySim.pdf", width=9, height=6)
par(mfrow=c(1,2))
plot(1:ageEpochs, Elist[[1]][1,], ylim = c(0, 4), cex = 0, xlab = "Epoch", ylab = "Entropy", cex.lab=1.5, xaxt="n")
axis(1, at=1:ageEpochs, labels=1:ageEpochs )
for(i in 1:nrow(Elist[[1]])){
  lines(1:ageEpochs, Elist[[1]][i,], lty = i, lwd = 1.5)
}
for(i in 1:nrow(Elist[[2]])){
  lines(1:ageEpochs, Elist[[2]][i,], lty = i, col = "red", lwd=1.5)
}


plot(1:ageEpochs, Slist[[1]][1,], cex = 0, ylim =c(.1, 80), xlab = "Epoch", ylab = "Similarity", cex.lab = 1.5, xaxt="n", log = "xy")
axis(1, at=1:ageEpochs, labels=1:ageEpochs )
for(i in 1:nrow(Slist[[1]])){
  lines(1:ageEpochs, Slist[[1]][i,], lty = i, lwd=1.5)
}
for(i in 1:nrow(Slist[[2]])){
  lines(1:ageEpochs, Slist[[2]][i,], lty = i, col = "red", lwd=1.5)
}
legend(2.8, 80, legend=c(TeX('0'),TeX('1')), title=TeX('\\alpha'),col = c("black", "red"), lty = 1, bty="n", lwd = 1.5 )
legend(2.8, 60, legend=c(TeX('.1'), TeX('.2'), TeX('.3'),TeX('.4'),TeX('.5')), title=TeX('\\beta'), lty = 1:5, bty="n", lwd=1.5)
#dev.off()
```

```{r Figure4, echo=FALSE,out.width="100%", fig.cap="Entropy and similarity measures computed from the cognitive representation at different epochs of development.",fig.show='hold',fig.align='center'}
knitr::include_graphics(c("EntropySim1000.01to.1.pdf"))
``` 

### Sparsening free association networks 

As noted above, @dubossarsky2017quantifying and others found that free association networks collected across the adult lifespan showed patterns of decreasing network degree, increasing average shortest path length, and decreasing clustering coefficient.  We can recover these results from the cognitive representation by simulating free association retrieval and network construction following the procedure used in past work  [@de2019small;@dubossarsky2017quantifying]. For each cognitive representation, we simulate 10 participants who retrieve three associates from each of 30 randomly chosen cues. The cues are sampled from the subset of concepts that have at least three associates in each epoch. The three associates are sampled without replacement for each participant and each cue is sampled in proportion to the associative strength encoded in the cognitive representation, i.e., the output from the Rescorla-Wagner training epochs. Negative association strengths are set to 0.  This produces a cue by associate matrix, with each cell indicating the number of times each associate was produced in response to each cue. From this matrix, the cue-by-cue similarities are computed using the cosine similarity between the vectors of their corresponding associates.  To transform these into unweighted and undirected networks, the median cue-by-cue similarity is computed across all epochs and, for each age, cue similarities below this median value are set to 0, and all other values are set to 1. This matrix is then transformed into a network on which degree (the number of connections), average shortest path length (the shortest number of edges between cues), and clustering coefficient (the proportion of a node's neighbors that are themselves connected) are computed. This entire process is repeated for 1000 different initial starting environments. The results are shown in Figure \@ref(fig:Figure5). The results follow the pattern found by @dubossarsky2017quantifying and others, with more learning leading to declining degree, rising average shortest path length, and falling clustering coefficient. 

Some readers may recognize that these results are predictable from the entropy and similarity judgments once we consider how the networks are constructed.  Because higher entropy leads to less predictable associative retrieval, this will weaken the associative strength between specific concepts in the retrieval data. If these weaker values are removed by some criteria for edge inclusion---as is common practice in network research using weighted edges [[e.g., ] @menczer2020first;@epskamp2018estimating;@agustin2024navigating;]---then  degree will fall and path lengths will increase. Furthermore, declining similarity judgements suggest that the entropy around nodes extends beyond the local community, with new edges formed that divert activation further afield. This in turn leads to the loss of local community structure and declining clustering coefficient. 
 
```{r assnet, eval=FALSE}
# Sample free associations for each cue, then produce cue x cue matrix (cosine similarity) and get back networks of cues to compute transitivity, degree, aspl

# Simulation to recreate environment and cognition and entropy/similarity measures

set.seed(1)
# Rescorla Wagner function 

rescorlaWagner <- function(vmat = vmat, cue, outcome, alpha=1, beta=.2) {
  # cue can be compound: e.g., cue = c("A", "B")
  # outcome can be compound: e.g., outcome = c("A", "B")
  cuevalues <- matrix(vmat[cue, ], nrow = length(cue))
  valueSums <- apply(cuevalues,2,sum )     # cumulative cue value
  # lambda = 1 when present 0 when absent
  lambda = as.numeric(rownames(vmat) %in% outcome)
  pError <- lambda - valueSums     # prediction error = observed - expected
  valueChange <- alpha * beta * pError # value change 
  vmat[cue, ] <- t(t(vmat[cue, ]) + valueChange)                   # update value
  return(vmat)
}


# World parameters (500/2000/200 for)
wordsInWorld=500
Associates = 2000 # Edges in environment
# Set learning events and age classes
learningEvents <- 200 
ageEpochs = 4
Worlds =5 
# Here we fix beta at .1 and use r^-1 (alpha = 1) for rank-based network
Betas = .1
alphas <- 1
alphai = 1
bis = 1
# Data storage for network metrics by age
# trans
transdev <- matrix(NA, nrow=4, ncol=Worlds)
# degree
degreedev <- matrix(NA, nrow=4, ncol=Worlds)
# aspl 
distancedev <- matrix(NA, nrow=4, ncol=Worlds)

# Each World creates a new environment and a new developmental learning trajectory with associations
for(woi in 1:Worlds){
  # Build the world
  x <- 1:wordsInWorld
  a = alphas[alphai] # set to 1 for association network demonstration
  pairs <- c()
  for(i in 1:Associates){
    pairs <- rbind(pairs, sample(x, size = 2, prob=x^(-a), replace = FALSE))
  }
  # Make graph from pairs
  ii <- graph_from_edgelist(pairs,directed=FALSE) 
  
  # Add isolates if number of vertices is not 500
  difamt = 500-length(V(ii))
  if (difamt > 0){
    ii <-  add_vertices(ii,difamt)
  }
  
  # Rename graph for learning representation 
  iis <- ii
  
  # Prepare Representation Matrix 
  
  n = length(V(iis))+1 # number of cues (words) + context cue
  
  # Initialize zero value matrix for learning
  vmat <- matrix(0, nrow = n, ncol = n)
  rownames(vmat) <- 1:n
  colnames(vmat) <- 1:n
  
  # Initialize metrics
  edgeE <- rep(NA, ageEpochs)
  nodeCount <- rep(NA, ageEpochs)
  ageNetworkList <- list(NULL)
  
  # Learn Representations across epochs 
  
  for(lage in 1:ageEpochs){
    # take fraction of environment that is learnable 
    #ageWords <- round(wordsInWorld*y[lage]/y[length(y)])
    ageWords <- wordsInWorld
    # make training data set
    traindata <- c()
    # sample edges from environment
    for(i in 1:learningEvents){
      traindata <- rbind(traindata, cue_outcome <- ends(iis, sample(E(iis), 1, prob=E(iis)$weight))) 
    }
    # keep list of first words learned in year 1
    if(lage == 1){
      firsttraindata <- traindata
    }
    # train on cue-outcome pairs
    for(i in 1:learningEvents){
      cue_outcome <- traindata[i,]
      cue_outcome<- sample(as.vector(cue_outcome))
      vmat <- rescorlaWagner(vmat, cue=c(n, cue_outcome[1]), outcome=cue_outcome[2], beta = Betas[bis]) 
    }
    # Make undirected graph from representation 
    gle <- graph_from_adjacency_matrix(vmat, weighted=TRUE, diag=FALSE, mode = "undirected")
    # Remove context cue
    gle <- igraph::delete_vertices(gle, n)
    nodeCount[lage] <- length(V(gle))
    # Remove negative edges
    negEdges <- which(E(gle)$weight < 0)
    gle <- igraph::delete_edges(gle, negEdges)
    # save learned representation
    ageNetworkList[[lage]] <- gle
  } # End development representation construction
  
  #### Compute associations for each network
  # Number of cues
  numcues = 30 
  # Make cue list from nodes with degree 3 or more across all four epochs
  deg3list.1 <- which(degree(ageNetworkList[[1]]) > 3)
  deg3list.2 <- which(degree(ageNetworkList[[2]]) > 3)
  deg3list.3 <- which(degree(ageNetworkList[[3]]) > 3)
  deg3list.4 <- which(degree(ageNetworkList[[4]]) > 3)
  # Take intersection of all lists
  gclist <- intersect(intersect(intersect(deg3list.1,deg3list.2), deg3list.3),deg3list.4)
  # Make cue list from sample of intersection of all lists
  cuelist <- sample(gclist, numcues)
  # store networks and matrices
  gcs <- list(NULL)
  gmats <- list(NULL)
  # For each age network 
  for(nits in 1:4){
    # Get weighted adjacency matrix for producing associates at each age
    getassmat <- get.adjacency(ageNetworkList[[nits]], attr="weight", sparse = FALSE)
    # Make empty cue x target matrix
    cxtm <- matrix(0, nrow= length(cuelist), ncol = length(V(ageNetworkList[[4]])))
    ## For number of participants 
    numparticipants = 10
    ## Generate up to 3 associates each 
    for(cuei in 1:length(cuelist)){
      # For number of participants
      for(partis in 1:numparticipants){
        # Sample from row of adjacency matrix in proportion to weight
        threeasss <- sample(1:ncol(cxtm), 3, prob=getassmat[cuelist[cuei],])
        # Add to cue x target matrix
        cxtm[cuei,threeasss] <- cxtm[cuei,threeasss] + 1
      } 
    }
    #### Compute cue x cue network
    cuesims <-  lsa::cosine(t(cxtm)) 
    # set diagonal to 0
    diag(cuesims) <- 0
    #### Compute stats on network
    gcs[[nits]] <- cuesims
    #### 
    gmats[[nits]] <- graph_from_adjacency_matrix(cuesims, weighted = TRUE, mode="undirected")
  } # end production of each cue x cue network across development
  
  ## compute median sim across all worlds as network threshold  
  medw <- median(unlist(gcs))
  # for each network threshold then compute values
  for(ip in 1:length(gcs)){
    nettodo <- gmats[[ip]]
    nettodo <- delete_edges(nettodo, which(E(nettodo)$weight < medw))
    E(nettodo)$weight <- 1
    # transitivity
    transdev[ip, woi] <- mean(igraph::transitivity(nettodo, type="localundirected"), na.rm=TRUE)
    # degree
    degreedev[ip, woi] <- mean(igraph::degree(nettodo))
    # aspl
    distancedev[ip, woi] <- igraph::mean_distance(nettodo)
  }
}
 
transdevalpha1 <- transdev

#pdf(file="NetworkAssociations1000.pdf", width = 7, height = 4) 
par(mfrow=c(1,3)) 
par(mar=c(5,5,2,2))
trm <- rowMeans(transdev)
dgrm <- rowMeans(degreedev)
dirm <- rowMeans(distancedev)
sdtrm <- apply(transdev, 1, sd)
sddgrm <- apply(degreedev, 1, sd)
sddirm <- apply(distancedev, 1, sd)
plot(dgrm, cex.lab=1.5, xaxt="n", ylab = "Degree", xlab = "Epoch", ylim=c(12, 18), xlim = c(.5, 4.5))
arrows(1:4, dgrm+sddgrm, 1:4, dgrm-sddgrm, angle=90, code=3, length = .1)
axis(1, at=1:4, labels=c("1","2","3","4") )
plot(dirm, cex.lab=1.5, xaxt="n", ylab="Average shortest path length", xlab="Epoch", ylim = c(1.3, 1.6), xlim = c(.5, 4.5))
axis(1, at=1:4, labels=c("1","2","3","4") )
arrows(1:4, dirm+sddirm, 1:4, dirm-sddirm, angle=90, code=3, length = .1)
plot(trm, cex.lab=1.5, xaxt="n", ylab = "Clustering Coefficient", xlab = "Epoch", ylim = c(0.5,.8), xlim=c(.5, 4.5))
arrows(1:4, trm+sdtrm, 1:4, trm-sdtrm, angle=90, code=3, length = .1)
axis(1, at=1:4, labels=c("1","2","3","4") )
#dev.off()
```

```{r Figure5, echo=FALSE,out.width="100%", fig.cap="The degree, average shortest path length, and clustering coefficient for networks of associations across the lifespan. Simulations were repeated for learning cognitive representations in 1000 different environments ($a=1$) with four training epochs each of 200 learning events each($\\beta=.1$). Representations were then each sampled from by 10 simulated participants who each retrieved 3 associates for each of 30 cues with probability proportional to the associative strengths output from the Rescorla-Wagner training epochs. The cosine similarity of cues was then computed from the cue by association matrix to produce associative networks for each epoch. These networks were then thresholded separately for each learning environment by the median similarity value across all ages. Error bars indicate one standard deviation. Results are consistent with Dubossarsky et al., 2017.", fig.show='hold',fig.align='center'}
knitr::include_graphics(c("NetworkAssociations1000.pdf"))
``` 



# Discussion

Aging is marked by complex and multi-faceted phenomenology. The enrichment account provided here demonstrates that key features of this phenomenology are predicted by cognitive enrichment. Specifically, the enrichment account demonstrates how learning enriches the cognitive representation which, when acted upon by various processes, gives rise to behavior commonly associated with cognitive aging. That is, as the representation becomes enriched and more densely interconnected through lifelong experience, the behaviors resulting from it lead to rising entropy, falling similarity judgments, and a sparsening of the free association network. 

The enrichment account is not meant to be a complete explanation of cognitive aging.  Rather, like any model, it puts guardrails on our ignorance. It does this by showing how many of the behaviors that we might have intuitively interpreted as evidence of cognitive and neural degradation are straightforward outcomes of learning and retrieval, based on well-established cognitive processes. Whereas we might have suspected degradation to explain sparsening free association networks, enrichment may be the more likely candidate. Indeed, we know enrichment must be occurring in association with rising crystallized intelligence, and thus the results presented here should be predicted even if degradation is influencing them in some as yet unknown way. Moreover, degradation can produce the opposite effect.  @BorgeHolthoefer:2011bg used degradation *not* to demonstrate diffusion of activation and greater slowing, but rather to demonstrate an increasing of activation between associates, producing hyper-priming, a well-documented behavior in patients with Alzheimer's Disease.  Nonetheless, the patterns of biological and neural change outlined in the introduction are themselves data. Any full account of cognitive aging must take this data into account. Ideally, we want to understand how these changes in neural architecture interact with enrichment to produce the behavioral variation that we see. With respect to model parsimony, enrichment may be sufficient to explain how fluid intelligence changes as a result of changes in crystallized intelligence, but our theories must also be parsimonious with respect to observed changes in the underlying neural architecture. 

The enrichment account is incomplete for several other reasons as well. One key extension is that lifelong experience with language follows Herdan-Heap's law [@brysbaert2016many]. Herdan-Heaps' law is the observation that the number of new word types is an increasing function of the number of word tokens, and this appears to be true for human experience with language as well. Thus the conceptual environment to which we are exposed may grow as we age.  This is easily added to the enrichment account by allowing the environment to grow over time. Future work should investigate various implications of this addition. A further limitation is that the enrichment account is not meant to characterize child development, which has special developmental features of its own. For example, early vocabulary acquisition is driven by a variety of processes including semantics, phonology, social pragmatics, and perceptual features [@jimenez2022semantic;@ciaglia2023investigating;@fourtassi2020growth;@yu2019infant;@engelthaler2017feature]. This different pattern of acquisition may extend into young adulthood, possibly as a result of standardized formal education [@dubossarsky2017quantifying]. Extending our understanding of the development of the cognitive representation from early childhood to late life remains for future work.

Despite these limitations, the fundamental mechanism of the enrichment account has empirical support. For example, the fan effect demonstrates that learning many relationships with a target concept reduces the speed of accessing any one of those relationships [@anderson1999fan]. This diffusion of activation is a general and well-understood outcome of spreading activation or random walker models [@siew2019spreadr;@abbott2015random]. Activation follows pathways and the more pathways there are the less targeted the activation. In addition, one can see the enrichment effect in natural experiments: @ramscar2017mismeasurement showed that individuals with more language experience (native speakers) were more impaired in paired-associative learning in that language than age-matched individuals with less experience (second language learners). This suggests the effect is not about age, but about enrichment.  

We also know that external clutter influences processing speed in older adults more strongly than young adults [@mccarley2012age;@amer2022cluttered]. This is consistent with higher entropy in the representation creating a more level-playing field for competition. If there is greater associative competition in older adults---because the associative entropy is higher---then older adults will suffer more from clutter in internal and external processing. This may explain the enhanced variability in resting-state brain synchronization among older adults [@jauny2022connectivity].  Moreover, because external cues gain their relevance via their encoded associations in memory [@easdale2019onset], this may also explain the impact of external clutter. Indeed, this was predicted by @Hasher:1988vg, who noted that, "If there is an age-related increase in the importance of one's personal values and experiences along with an age-related increase in the tendency to apply these concerns to a wider range of information, more information...is likely to enter working memory." Here, we might only add that the increase may be partly due to a proliferation and rising entropy of associations. The attentional contribution to clutter on aging memory, as elegantly described by @amer2022cluttered, could therefore be a consequence of enrichment: the activation strengths associated with extraneous and potentially irrelevant information have a greater relative competitive advantage in individuals with more enriched representations, making older individuals more susceptible to clutter driven by both internal and external distractions.

One false challenge to the enrichment account is that individuals with higher education and occupational attainment are less likely to experience late-life cognitive decline [@stern1994influence;@lovden2020education]. This is known to be partially a consequence of compensation accorded by skills or strategic repertoires, what is called cognitive reserve [@scarmeas2003cognitive]. Additionally, however, there is ample evidence that differences in cognitive skills emerge early in life, prior to education, and therefore lay the foundation for educational attainment later in life [@lovden2020education;@deary2004impact]. If differences in processing speed at an early age influence educational attainment at a later age, then slowing later as a consequence of education will be confounded by early differences in processing. Early processing advantages may not be a result of experience at all. IQ is correlated with brain volume [@pietschnig2022differing] and is strongly heritable [@peper2007genetic]. Furthermore, measures of 'brain age' in late life are well-predicted by indicators present in early life [@vidal2021individual]. Thus, one may sensibly conclude that the capacity for long-term resilience also predicts lifelong achievement.  Nonetheless, if we believe that formal education (or occupational attainment) is an indicator of increased associative density (not just in quality, but quantity), then an ideal test might be to investigate twins who differ in educational enrichment and are then evaluated on age-related cognitive decline. The @ramscar2017mismeasurement study on age-matched bilinguals and monolinguals is another approach, but more research of this kind is needed.  What kinds of learning matter for enrichment is an open question.  Is rewatching the 11 seasons of the 1970s TV series M\*A\*S\*H  (approximately 125 hours runtime) different from an initial reading of the complete works of Thomas Mann (approximately 125 hours reading time)?  If enrichment is about the quantity of associations, and not the quality of associations (if such quality could be objectively measured), then the difference may not matter. 

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
